{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Integrating WOFOST Simulation with Bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Platform not recognized, using system temp directory for PCSE settings.\n",
      "Platform not recognized, using system temp directory for PCSE settings.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import math\n",
    "from math import exp, log, sqrt\n",
    "import csv\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pcse.fileinput import CABOFileReader\n",
    "from pcse.db import NASAPowerWeatherDataProvider\n",
    "from pcse.base import ParameterProvider\n",
    "from pcse.engine import Engine\n",
    "\n",
    "from src.actions import AgroActions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some experts, starting with some silly ones..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An expert that recommends all actions with equal probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformExpert:\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "        self.n_actions = len(self.actions)\n",
    "\n",
    "    def give_advice(self):\n",
    "        return np.ones(self.n_actions) / self.n_actions\n",
    "\n",
    "    def update(self, args):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stubborn Expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An expert that randomly picks an action and sticks with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert:\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "        self.n_actions = len(self.actions)\n",
    "        self.stubborn_action = np.random.default_rng().choice(self.n_actions, shuffle=False)\n",
    "\n",
    "    def give_advice(self):\n",
    "        advice = np.zeros(self.n_actions)\n",
    "        advice[self.stubborn_action] = 1\n",
    "        return advice\n",
    "\n",
    "    def update(self, args):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idle Expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An expert that recommends doing nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoActionExpert(Expert):\n",
    "    def __init__(self, actions):\n",
    "        super().__init__(actions)\n",
    "        self.stubborn_action = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized WOFOST Expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An expert that recommends each action with probability that is proportional to the WOFOST yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WofostExpert(Expert):\n",
    "    def __init__(self, actions):\n",
    "        super().__init__(actions)\n",
    "        self.yields = np.zeros(self.n_actions)\n",
    "\n",
    "    def update(self, yields):\n",
    "        self.yields = yields\n",
    "\n",
    "    def give_advice(self):\n",
    "        advice = self.yields / np.sum(self.yields)\n",
    "        return advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturbed Randomized WOFOST Expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This expert is similar to the randomized WOFOST expert but the probability distribution is perturbed with Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerturbedWofostExpert(WofostExpert):\n",
    "    def __init__(self, actions, noise_scale=1.0):\n",
    "        super().__init__(actions)\n",
    "        if not isinstance(noise_scale, float):\n",
    "            raise TypeError('noise_scale must be float')\n",
    "        if not noise_scale >= 0:\n",
    "            raise ValueError('noise_scale must be nonnegative')\n",
    "        self.noise_scale = noise_scale\n",
    "\n",
    "    def give_advice(self):\n",
    "        advice = self.yields / np.sum(self.yields)\n",
    "        advice = advice + np.random.default_rng().normal(0, self.noise_scale, self.n_actions)\n",
    "        advice = np.clip(advice, 0, 1e3)\n",
    "        advice = advice / np.sum(advice)\n",
    "        return advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complementary WOFOST Expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An expert that copys the opposite of the WOFOST expert's recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplementaryWofostExpert(WofostExpert):\n",
    "    def __init__(self, actions):\n",
    "        super().__init__(actions)\n",
    "\n",
    "    def give_advice(self):\n",
    "        advice = 1 - self.yields / np.sum(self.yields)\n",
    "        advice = advice / np.sum(advice)\n",
    "        return advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum WOFOST Expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An expert that recommends the action that gives the lowest yield. The worst expert ever..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinWofostExpert(WofostExpert):\n",
    "    def __init__(self, actions):\n",
    "        super().__init__(actions)\n",
    "\n",
    "    def give_advice(self):\n",
    "        idx = np.argmin(self.yields)\n",
    "        advice = np.zeros(self.n_actions)\n",
    "        advice[idx] = 1\n",
    "        return advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum WOFOST Expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An expert that recommends the action that gives the highest yield. The best expert ever!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxWofostExpert(WofostExpert):\n",
    "    def __init__(self, actions):\n",
    "        super().__init__(actions)\n",
    "\n",
    "    def give_advice(self):\n",
    "        idx = np.argmax(self.yields)\n",
    "        advice = np.zeros(self.n_actions)\n",
    "        advice[idx] = 1\n",
    "        return advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturbed Maximum WOFOST Expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This expert is similar to the maximum WOFOST expert but the probability distribution is perturbed with Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerturbedMaxWofostExpert(WofostExpert):\n",
    "    def __init__(self, actions, noise_scale=1.0):\n",
    "        super().__init__(actions)\n",
    "        if not isinstance(noise_scale, float):\n",
    "            raise TypeError('noise_scale must be float')\n",
    "        if not noise_scale >= 0:\n",
    "            raise ValueError('noise_scale must be nonnegative')\n",
    "        self.noise_scale = noise_scale\n",
    "\n",
    "    def give_advice(self):\n",
    "        idx = np.argmax(self.yields)\n",
    "        advice = np.zeros(self.n_actions)\n",
    "        advice[idx] = 1\n",
    "        advice = advice + np.random.default_rng().normal(0, self.noise_scale, self.n_actions)\n",
    "        advice = np.clip(advice, 0, 1e3)\n",
    "        advice = advice / np.sum(advice)\n",
    "        return advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up WOFOST Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of demonstration, we use data of the Netherlands. We use TWSO as yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wofost:\n",
    "    @staticmethod\n",
    "    def init_wofost():\n",
    "        data_dir = os.path.join(os.getcwd(), '../simulation/default_data')\n",
    "        crop_file_name = 'crop.cab'\n",
    "        soil_file_name = 'soil.cab'\n",
    "        site_file_name = 'site.cab'\n",
    "        config_file_name = 'WLP_NPK.conf'\n",
    "\n",
    "        soildata = CABOFileReader(os.path.join(data_dir, soil_file_name))\n",
    "        sitedata = CABOFileReader(os.path.join(data_dir, site_file_name))\n",
    "        cropdata = CABOFileReader(os.path.join(data_dir, crop_file_name))\n",
    "        config = os.path.join(data_dir, config_file_name)\n",
    "\n",
    "        params = ParameterProvider(cropdata, sitedata, soildata)\n",
    "        latitude, longitude = 51.97, 5.67\n",
    "        wdp = NASAPowerWeatherDataProvider(latitude, longitude)\n",
    "\n",
    "        return params, wdp, config\n",
    "\n",
    "    @staticmethod\n",
    "    def run_wofost(agromanagement, params, wdp, config):\n",
    "        wofost = Engine(params, wdp, agromanagement, config)  # WLP_NPK\n",
    "        wofost.run_till_terminate()\n",
    "        r = wofost.get_summary_output()\n",
    "        return r[0][\"TWSO\"]  # Can be changed according to crop choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the environment that creates rewards and evaluates actions. The WOFOST simulator is integrated into here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \"\"\"Generate rewards and record history.\"\"\"\n",
    "\n",
    "    def __init__(self, actions, experts, record_best_expert=False, **kwargs):\n",
    "        self.actions = actions\n",
    "        self.n_actions = len(self.actions)\n",
    "        self.experts = experts\n",
    "        # Wofost related\n",
    "        params, wdp, config = Wofost.init_wofost()\n",
    "        self.wofost_params = [params, wdp, config]\n",
    "        self.yields = np.empty(self.n_actions)\n",
    "\n",
    "        self.current_rewards = np.empty(self.n_actions)\n",
    "        self.record_best_expert = record_best_expert\n",
    "        if 'means' in kwargs:\n",
    "            assert len(kwargs['means']) == self.n_actions, 'means and actions must be the same length'\n",
    "            self.means = kwargs['means']\n",
    "        if 'alphas' in kwargs:\n",
    "            assert len(kwargs['alphas']) == self.n_actions, 'alphas and actions must be the same length'\n",
    "            self.alphas = kwargs['alphas']\n",
    "        if 'betas' in kwargs:\n",
    "            assert len(kwargs['betas']) == self.n_actions, 'betas and actions must be the same length'\n",
    "            self.betas = kwargs['betas']\n",
    "        self.t = 1\n",
    "        self.history = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_random_year():\n",
    "        # Sample year from a non-stationary distribution\n",
    "        random.seed(time.time())\n",
    "        years_complete_weather = list(range(1984, 2000)) + [2002] + list(range(2004, 2016)) + [2017, 2019]\n",
    "        year = random.choice(years_complete_weather)\n",
    "        return year\n",
    "\n",
    "    def update(self):\n",
    "        year = self.sample_random_year()\n",
    "        self.actions, _ = AgroActions().create_actions([0, 1, 4, 7], [0, 15], year=year)\n",
    "        # Run Wofost to obtain yield for each action\n",
    "        self.yields = np.zeros(self.n_actions)\n",
    "        for i, action in enumerate(self.actions):\n",
    "            self.yields[i] = Wofost.run_wofost(action, *self.wofost_params)\n",
    "\n",
    "        for expert in self.experts:\n",
    "            expert.update(self.yields)\n",
    "\n",
    "    def reward_bernoulli(self, action_id):\n",
    "        self.current_rewards = (np.random.uniform(size=self.n_actions) < self.means) * 1\n",
    "        return self.current_rewards[action_id]\n",
    "\n",
    "    def reward_beta(self, action_id):\n",
    "        self.current_rewards = np.random.default_rng().beta(self.alphas, self.betas)\n",
    "        return self.current_rewards[action_id]\n",
    "\n",
    "    def reward_wofost(self, action_id):\n",
    "        self.current_rewards = self.yields / np.sum(self.yields)\n",
    "        return self.current_rewards[action_id]\n",
    "\n",
    "    def add_history(self, action_id, reward, expert_weights, advice):\n",
    "        expert_weights = expert_weights / np.sum(expert_weights)\n",
    "        expert_mean_rewards = np.matmul(advice, self.current_rewards)\n",
    "        self.history[self.t] = {'action_id': action_id, 'reward': reward,\n",
    "                                'expert_weights': expert_weights, 'expert_mean_rewards': expert_mean_rewards}\n",
    "        if self.record_best_expert:\n",
    "            max_val = np.max(expert_mean_rewards)\n",
    "            best_expert_ids = []\n",
    "            for expert_id, expert_mean_reward in enumerate(expert_mean_rewards):\n",
    "                if abs(expert_mean_reward - max_val) < 1e-6:\n",
    "                    best_expert_ids.append(expert_id)\n",
    "            self.history[self.t].update({'best_expert_ids': best_expert_ids,\n",
    "                                         'best_expert_mean_reward': max_val})\n",
    "        self.t += 1\n",
    "\n",
    "    def save_history_to_csv(self, file_dir='', filename='history', timestamp=False):\n",
    "        if timestamp:\n",
    "            filename += f'_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "        if '.csv' not in filename:\n",
    "            filename += '.csv'\n",
    "        with open(file_dir + filename, mode='w') as file:\n",
    "            fieldnames = ['time', 'action_id', 'reward', 'expert_weights', 'expert_mean_rewards']\n",
    "            if self.record_best_expert:\n",
    "                fieldnames.extend(['best_expert_ids', 'best_expert_mean_reward'])\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(fieldnames)\n",
    "            for t in range(1, len(self.history) + 1):\n",
    "                record = self.history[t]\n",
    "                if self.record_best_expert:\n",
    "                    writer.writerow([t, record['action_id'], record['reward'],\n",
    "                                     record['expert_weights'], record['expert_mean_rewards'],\n",
    "                                     record['best_expert_ids'], record['best_expert_mean_reward']])\n",
    "                else:\n",
    "                    writer.writerow([t, record['action_id'], record['reward'],\n",
    "                                     record['expert_weights'], record['expert_mean_rewards']])\n",
    "\n",
    "    def save_actions_to_csv(self, file_dir='', filename='actions', timestamp=False):\n",
    "        if timestamp:\n",
    "            filename += f'_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "        if '.csv' not in filename:\n",
    "            filename += '.csv'\n",
    "        with open(file_dir + filename, mode='w') as file:\n",
    "            fieldnames = ['action_id', 'event_signal', 'name', 'comment', 'events_table']\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for action_id, action in enumerate(self.actions):\n",
    "                action_dict = {'action_id': action_id}\n",
    "                campaign_start_date = list(action[0].keys())[0]\n",
    "                action_description = action[0][campaign_start_date]['TimedEvents']\n",
    "                if len(action_description) > 0:\n",
    "                    for event_id in range(len(action_description)):\n",
    "                        events_table = action_description[event_id]['events_table']\n",
    "                        for entry_id in range(len(events_table)):\n",
    "                            entry = events_table[entry_id]\n",
    "                            date = list(entry.keys())[0]\n",
    "                            events_table[entry_id] = {f'{date.month}/{date.day}': entry[date]}\n",
    "                        action_dict.update(action_description[event_id])\n",
    "                        writer.writerow(action_dict)\n",
    "                else:\n",
    "                    writer.writerow(action_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Exp4.R Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the bandit algorithm where learning takes place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exp4R:\n",
    "    def __init__(self, actions, experts, T, delta=.1, rho=None):\n",
    "        if not isinstance(actions, (list, tuple)):\n",
    "            raise TypeError('actions must be either list or tuple')\n",
    "        if not len(actions) > 0:\n",
    "            raise ValueError('actions cannot be empty')\n",
    "        self.actions = actions\n",
    "        self.n_actions = len(self.actions)\n",
    "\n",
    "        if not isinstance(experts, (list, tuple)):\n",
    "            raise TypeError('experts must be either list or tuple')\n",
    "        if not len(experts) > 0:\n",
    "            raise ValueError('experts cannot be empty')\n",
    "        self.experts = experts\n",
    "        self.n_experts = len(experts)\n",
    "\n",
    "        if not isinstance(T, int):\n",
    "            raise TypeError('T must be int')\n",
    "        if not T > 0:\n",
    "            raise ValueError('T must be positive')\n",
    "        self.T = T\n",
    "\n",
    "        if not isinstance(delta, float):\n",
    "            raise TypeError('delta must be float')\n",
    "        if not 0 < delta <= 1:\n",
    "            raise ValueError('delta must be positive and no larger than 1')\n",
    "        self.delta = delta\n",
    "\n",
    "        self.beta = sqrt(log(2 * self.n_experts / self.delta) / self.n_actions / self.T)\n",
    "        assert self.beta ** 2 <= math.e - 2, 'ln(2N/delta) <= (e-2)KT must hold'\n",
    "\n",
    "        if rho is None:\n",
    "            rho = sqrt(log(self.n_experts) / self.n_actions / self.T)\n",
    "        elif not isinstance(rho, float):\n",
    "            raise TypeError('rho must be float')\n",
    "        if not 0 < rho <= 1 / self.n_actions:\n",
    "            raise ValueError(f'rho must be positive and no larger than {1 / self.n_actions}')\n",
    "        else:\n",
    "            self.rho = rho\n",
    "\n",
    "        if not 49 * self.n_actions * log(2 * self.n_experts / self.delta) < self.T:\n",
    "            warnings.warn('The regret upper bound is vacuous for the inputs given.\\n'\n",
    "                          'Try one or multiple of the following options:\\n'\n",
    "                          '- increasing time horizon\\n'\n",
    "                          '- increasing delta\\n'\n",
    "                          '- reducing the number of actions\\n'\n",
    "                          '- reducing the number of experts')\n",
    "\n",
    "        self.t = 1\n",
    "\n",
    "        self.expert_weights = np.ones(self.n_experts)\n",
    "        self.expert_thresholds = np.zeros(self.n_experts)\n",
    "\n",
    "        self.advice = np.empty((self.n_experts, self.n_actions))\n",
    "        self.action_pmf = np.empty(self.n_actions)\n",
    "\n",
    "    def get_advice(self):\n",
    "        for expert_id in range(self.n_experts):\n",
    "            self.advice[expert_id] = self.experts[expert_id].give_advice()\n",
    "            assert 1 - np.sum(self.advice[expert_id]) <= 1e-4, \\\n",
    "                f'incorrect advice distribution, expert_id: {expert_id}'\n",
    "\n",
    "    def combine_advice(self):\n",
    "        self.action_pmf = ((1 - self.n_actions * self.rho) * np.matmul(self.expert_weights, self.advice)\n",
    "                           / np.sum(self.expert_weights) + self.rho)\n",
    "\n",
    "    def sample_action_id(self):\n",
    "        return np.random.default_rng().choice(self.n_actions, p=self.action_pmf, shuffle=False)\n",
    "\n",
    "    def update_weights(self, action_id, reward):\n",
    "        mean_coeff = reward / self.action_pmf[action_id]\n",
    "        for expert_id in range(self.n_experts):\n",
    "            uncertainty = np.sum(np.divide(self.advice[expert_id], self.action_pmf))\n",
    "            self.expert_weights[expert_id] *= exp(self.rho / 2 * (mean_coeff * self.advice[expert_id][action_id]\n",
    "                                                                  + self.beta * uncertainty))\n",
    "            self.expert_thresholds[expert_id] += uncertainty\n",
    "        self.t += 1\n",
    "\n",
    "    def get_expert_thresholds(self):\n",
    "        self.expert_thresholds = ((1 + self.expert_thresholds / self.n_actions / self.T)\n",
    "                                  * log(2 * self.n_experts / self.delta))\n",
    "\n",
    "    def threshold_test(self):\n",
    "        self.get_expert_thresholds()\n",
    "        expert_weight_ranking = np.flip(self.expert_weights.argsort())\n",
    "        pairwise_ranking = []\n",
    "        for i in range(self.n_experts-1):\n",
    "            better_id = expert_weight_ranking[i]\n",
    "            j = self.n_experts - 1\n",
    "            while j > i:\n",
    "                worse_id = expert_weight_ranking[j]\n",
    "                diff = log(self.expert_weights[better_id]) - log(self.expert_weights[worse_id])\n",
    "                if diff > self.expert_thresholds[better_id]:\n",
    "                    pairwise_ranking.append((better_id, worse_id))\n",
    "                j -= 1\n",
    "        if len(pairwise_ranking) > 0:\n",
    "            message = 'Estimated pairwise expert ranking as follows:'\n",
    "            for better_id, worse_id in pairwise_ranking:\n",
    "                message += f'\\nExpert {better_id} better than Expert {worse_id}'\n",
    "        else:\n",
    "            message = 'Cannot decide on pairwise expert ranking...'\n",
    "        print(message)\n",
    "\n",
    "    def print_regret_upper_bound(self):\n",
    "        regret_upper_bound = 7 * sqrt(self.n_actions * self.T * log(2 * self.n_experts / self.delta))\n",
    "        print(f'Regret upper bound: {regret_upper_bound}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to decide on the time horizon, actions, and experts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORD_BEST_EXPERT = True\n",
    "TIME_HORIZON = 3000\n",
    "ACTIONS, _ = AgroActions().create_actions([0, 1, 4, 7], [0, 15], year=2019)\n",
    "EXPERTS = ([UniformExpert(ACTIONS)]\n",
    "           + [Expert(ACTIONS) for _ in range(3)]\n",
    "           + [NoActionExpert(ACTIONS)]\n",
    "           + [WofostExpert(ACTIONS)]\n",
    "           + [PerturbedWofostExpert(ACTIONS, 1e-2)]\n",
    "           + [PerturbedWofostExpert(ACTIONS, 1.0)]\n",
    "           + [ComplementaryWofostExpert(ACTIONS)]\n",
    "           + [MinWofostExpert(ACTIONS)]\n",
    "           + [MaxWofostExpert(ACTIONS)]\n",
    "           + [PerturbedMaxWofostExpert(ACTIONS, 1e-2)]\n",
    "           + [PerturbedMaxWofostExpert(ACTIONS, 1.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(ACTIONS, EXPERTS, RECORD_BEST_EXPERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the action details to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.save_actions_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   action_id event_signal                           name  \\\n",
      "0          0          NaN                            NaN   \n",
      "1          1    apply_npk  Timed N/P/K application table   \n",
      "2          2     irrigate   Irrigation application table   \n",
      "3          3     irrigate   Irrigation application table   \n",
      "4          3    apply_npk  Timed N/P/K application table   \n",
      "\n",
      "                           comment  \\\n",
      "0                              NaN   \n",
      "1  All fertilizer amounts in kg/ha   \n",
      "2     All irrigation amounts in cm   \n",
      "3     All irrigation amounts in cm   \n",
      "4  All fertilizer amounts in kg/ha   \n",
      "\n",
      "                                        events_table  \n",
      "0                                                NaN  \n",
      "1  [{'1/1': {'N_amount': 15, 'P_amount': 15, 'K_a...  \n",
      "2  [{'1/1': {'amount': 10, 'efficiency': 0.7}}, {...  \n",
      "3  [{'1/1': {'amount': 10, 'efficiency': 0.7}}, {...  \n",
      "4  [{'1/1': {'N_amount': 15, 'P_amount': 15, 'K_a...  \n"
     ]
    }
   ],
   "source": [
    "df_actions = pd.read_csv('actions.csv')\n",
    "print(df_actions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_id         0\n",
      "event_signal    NaN\n",
      "name            NaN\n",
      "comment         NaN\n",
      "events_table    NaN\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_actions.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_id                                                       1\n",
      "event_signal                                            apply_npk\n",
      "name                                Timed N/P/K application table\n",
      "comment                           All fertilizer amounts in kg/ha\n",
      "events_table    [{'1/1': {'N_amount': 15, 'P_amount': 15, 'K_a...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_actions.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_id                                                       2\n",
      "event_signal                                             irrigate\n",
      "name                                 Irrigation application table\n",
      "comment                              All irrigation amounts in cm\n",
      "events_table    [{'1/1': {'amount': 10, 'efficiency': 0.7}}, {...\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_actions.loc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also initialize the Exp4.R algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp4r = Exp4R(ACTIONS, EXPERTS, TIME_HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the game starts, we can provide a high-probability upper bound on the regret of Exp4.R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regret upper bound: 2557.2175500090448\n"
     ]
    }
   ],
   "source": [
    "exp4r.print_regret_upper_bound()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At time $t = 1,2, \\dots , T$,\n",
    "1. The environment sets a reward vector $r(t) \\in [0, 1]^K$ where $r_a(t)$ is the reward of action $a$.\n",
    "1. Each expert $i$ provides their advice $\\xi_i(t)$, which is a probability vector over actions.\n",
    "1. After observing all experts’ advice but not the rewards, Exp4.R combines the advice and samples an action $a(t)$.\n",
    "1. Exp4.R receives the reward $r_{a(t)}(t)$ from the environment and no other information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/3000 [00:15<4:13:08,  5.07s/it]"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(TIME_HORIZON)):\n",
    "    env.update()\n",
    "    exp4r.get_advice()\n",
    "    exp4r.combine_advice()\n",
    "    action_id = exp4r.sample_action_id()\n",
    "    reward = env.reward_wofost(action_id)\n",
    "    env.add_history(action_id, reward, exp4r.expert_weights, exp4r.advice)\n",
    "    exp4r.update_weights(action_id, reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the history of the game to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.save_history_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_history = pd.read_csv('history.csv')\n",
    "print(df_history.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which experts gave good advice? Depending on the setting and stochasticity, we may or may not be able to answer this question..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp4r.threshold_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, FFMpegWriter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadCSV:\n",
    "    \"\"\"Read simulation data into df.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        assert df.notnull().values.all(), 'Missing values'\n",
    "        for col in {'expert_weights', 'expert_mean_rewards'}:\n",
    "            df[col] = df[col].str.strip('[]').apply(lambda x: np.array(x.split()).astype(float))\n",
    "        self.df = df\n",
    "\n",
    "    def add_regret(self):\n",
    "        assert 'best_expert_mean_reward' in self.df.columns, 'best_expert_mean_reward unrecorded'\n",
    "        if 'regret' not in self.df.columns:\n",
    "            self.df['regret'] = self.df['best_expert_mean_reward'] - self.df['reward']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first check if we were correct about the regret bound..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(csv_path, y, ylabel=None, cumsum=True,\n",
    "                     style='whitegrid', save=False, filename_tag='', timestamp=False, plot_path=''):\n",
    "    \"\"\"Plot time series\"\"\"\n",
    "\n",
    "    data = ReadCSV(csv_path)\n",
    "    if y == 'regret':\n",
    "        data.add_regret()\n",
    "    data.df.set_index('time', inplace=True)\n",
    "    s = data.df[y]\n",
    "    if cumsum:\n",
    "        s = s.cumsum()\n",
    "    sns.set_theme(style=style)\n",
    "    sns.set(rc={'figure.figsize':(10, 8)})\n",
    "    lineplot = sns.lineplot(data=s, palette=\"tab10\", linewidth=3)\n",
    "    lineplot.set_xlabel('Time', fontsize=20)\n",
    "    if ylabel is None:\n",
    "        ylabel = f'Cumulative {y}'\n",
    "    lineplot.set_ylabel(ylabel, fontsize=20)\n",
    "    lineplot.tick_params(labelsize=15)\n",
    "    if save:\n",
    "        if filename_tag == '':\n",
    "            filename_tag = y\n",
    "        if timestamp:\n",
    "            filename = f'time_series_{filename_tag}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.pdf'\n",
    "        else:\n",
    "            filename = f'time_series_{filename_tag}.pdf'\n",
    "        plt.savefig(plot_path + filename, transparent=True)\n",
    "    plt.show()\n",
    "    plt.pause(3)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'history.csv'\n",
    "plot_time_series(csv_path, 'regret', 'Regret', cumsum=True, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the weights on the experts evolve over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animation_bar_chart(csv_path, xticklabels=None, ylim=None, sort_by_reward=True,\n",
    "                        style='whitegrid', save=False, filename_tag='expert_weight', timestamp=False, plot_path=''):\n",
    "    \"\"\"Animate bar chart\"\"\"\n",
    "\n",
    "    data = ReadCSV(csv_path)\n",
    "    data.df.set_index('time', inplace=True)\n",
    "    expert_weights = data.df['expert_weights']\n",
    "    n_experts = len(expert_weights.loc[1])\n",
    "    sns.set_theme(style=style)\n",
    "    if xticklabels is None:\n",
    "        xticklabels = np.arange(n_experts)\n",
    "        rotate_xticklabels = True\n",
    "    else:\n",
    "        rotate_xticklabels = False\n",
    "    x = np.arange(n_experts)\n",
    "    if ylim is None:\n",
    "        expert_final_weights = expert_weights.loc[len(expert_weights)]\n",
    "        ylim = (0, min(1, 1.1*np.max(expert_final_weights)))\n",
    "    if sort_by_reward:\n",
    "        expert_mean_rewards = np.array(data.df['expert_mean_rewards'].values.tolist())\n",
    "        expert_mean_rewards_over_time = np.sum(expert_mean_rewards, axis=0) / len(expert_mean_rewards)\n",
    "        sorted_ids = expert_mean_rewards_over_time.argsort()\n",
    "        for t in range(1, len(expert_weights)+1):\n",
    "            expert_weights.at[t] = expert_weights.at[t][sorted_ids]\n",
    "        xticklabels = np.array(xticklabels)[sorted_ids]\n",
    "    width = .6\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    def init():\n",
    "        ax.clear()\n",
    "        ax.set_xlim(-.5, n_experts-.5)\n",
    "        ax.set_ylim(*ylim)\n",
    "\n",
    "    def animate(frame_id):\n",
    "        init()\n",
    "        time = frame_id + 1\n",
    "        ax.bar(x, expert_weights.loc[time], width)\n",
    "        ax.set_xlabel('Expert')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_ylabel('Weight')\n",
    "        ax.set_title(f'Time {time}')\n",
    "        if rotate_xticklabels:\n",
    "            ax.set_xticklabels(xticklabels)\n",
    "        else:\n",
    "            ax.set_xticklabels(xticklabels, rotation=45, ha='right')\n",
    "        fig.tight_layout()\n",
    "\n",
    "    anim = FuncAnimation(fig, animate, init_func=init, frames=len(expert_weights), interval=200, repeat=False)\n",
    "\n",
    "    if save:\n",
    "        if timestamp:\n",
    "            filename = f'animated_bar_chart_{filename_tag}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.mp4'\n",
    "        else:\n",
    "            filename = f'animated_bar_chart_{filename_tag}.mp4'\n",
    "        FFwriter = FFMpegWriter(fps=10)\n",
    "        anim.save(plot_path + filename, writer=FFwriter)\n",
    "    plt.show()\n",
    "    plt.pause(3)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticklabels = ['Uniform', 'Stubborn 1', 'Stubborn 2', 'Stubborn 3',\n",
    "               'No Action', 'WOFOST Randomized', 'WOFOST SP', 'WOFOST BP',\n",
    "               'WOFOST Complement', 'WOFOST Min', 'WOFOST Max', 'WOFOST Max SP', 'WOFOST Max BP']\n",
    "animation_bar_chart(csv_path, xticklabels=xticklabels, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now focus on the final weights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart(csv_path, xticklabels=None, sort_by_reward=True,\n",
    "                   style='whitegrid', save=False, filename_tag='expert_weight_reward', timestamp=False, plot_path=''):\n",
    "    \"\"\"Plot bar chart\"\"\"\n",
    "\n",
    "    data = ReadCSV(csv_path)\n",
    "    expert_final_weights = data.df.loc[data.df.index[-1], 'expert_weights']\n",
    "    expert_mean_rewards = np.array(data.df['expert_mean_rewards'].values.tolist())\n",
    "    expert_mean_rewards_over_time = np.sum(expert_mean_rewards, axis=0) / len(expert_mean_rewards)\n",
    "    sns.set_theme(style=style)\n",
    "    if xticklabels is None:\n",
    "        xticklabels = np.arange(len(expert_final_weights))\n",
    "        rotate_xticklabels = True\n",
    "    else:\n",
    "        rotate_xticklabels = False\n",
    "    x = np.arange(len(expert_final_weights))\n",
    "    if sort_by_reward:\n",
    "        sorted_ids = expert_mean_rewards_over_time.argsort()\n",
    "        expert_final_weights = expert_final_weights[sorted_ids]\n",
    "        expert_mean_rewards_over_time = expert_mean_rewards_over_time[sorted_ids]\n",
    "        xticklabels = np.array(xticklabels)[sorted_ids]\n",
    "    width = .35\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x - width / 2, expert_final_weights, width, label='Final weight')\n",
    "    ax.bar(x + width / 2, expert_mean_rewards_over_time, width, label='Mean reward per time step')\n",
    "    ax.set_xlabel('Expert', fontsize=20)\n",
    "    ax.set_xticks(x)\n",
    "    if rotate_xticklabels:\n",
    "        ax.set_xticklabels(xticklabels, fontsize=18)\n",
    "    else:\n",
    "        ax.set_xticklabels(xticklabels, rotation=45, ha='right')\n",
    "    ax.legend(fontsize=20)\n",
    "    fig.tight_layout()\n",
    "    if save:\n",
    "        if timestamp:\n",
    "            filename = f'bar_chart_{filename_tag}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.pdf'\n",
    "        else:\n",
    "            filename = f'bar_chart_{filename_tag}.pdf'\n",
    "        plt.savefig(plot_path + filename, transparent=True)\n",
    "    plt.show()\n",
    "    plt.pause(3)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_chart(csv_path, xticklabels=xticklabels, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
